# Architecture Documentation

## Overview

Samba2 implements two novel neural network architectures using the Lux.jl framework:
1. **SWAttention**: Multi-head attention with normalized sigmoid activation
2. **OSSM**: Oscillatory State Space Model with learnable damped oscillators

Both are designed as standalone Lux layers that can be composed into larger networks.

---

## LLaDA Model (Text Diffusion LLM)

The main model to be trained is **LLaDAModel** - a discrete text diffusion language model using Ossamma architecture.

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                      LLaDAModel                               â”‚
                          â”‚              Text Diffusion Language Model                    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                           â”‚                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Token    â”‚             â”‚   Position    â”‚           â”‚    Time       â”‚
                    â”‚ Embedding â”‚             â”‚   Embedding   â”‚           â”‚  Embedding    â”‚
                    â”‚(vocabâ†’dim)â”‚             â”‚  (posâ†’dim)    â”‚           â”‚ (sinusoidal   â”‚
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  + MLP)       â”‚
                          â”‚                           â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
                                       â”‚ + (add)                        mask_ratio t âˆˆ [0,1]
                                       â–¼                                          â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
                          â”‚     hidden (d, L, B)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                          â•”â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•â•—
                          â•‘                         â•‘
                          â•‘  OssammaBlock Ã— N       â•‘  (N = number_of_layers)
                          â•‘                         â•‘
                          â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•
                                       â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚      LayerNorm          â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Output Head (Dense)   â”‚
                          â”‚     dim â†’ vocab_size    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   Logits (V, L, B)      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OssammaBlock Detail

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                      OssammaBlock                                            â•‘
â•‘       Oscillatory State Space Attention Masked Mixer Architecture                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                             â•‘
â•‘   Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Residual       â•‘
â•‘      â”‚                                                                           â”‚          â•‘
â•‘      â–¼                                                                           â”‚          â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚          â•‘
â•‘   â”‚  Time-Conditioned LayerNorm   â”‚â—„â”€â”€ time_emb                                  â”‚          â•‘
â•‘   â”‚   (scale, shift, Î±_bias)      â”‚                                              â”‚          â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚          â•‘
â•‘                   â”‚ x_norm                                                       â”‚          â•‘
â•‘      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚          â•‘
â•‘      â”‚                         â”‚                                                 â”‚          â•‘
â•‘      â–¼                         â”‚                                                 â”‚          â•‘
â•‘ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚          â•‘
â•‘ â”‚         Global-Spectral GLU Branch             â”‚                               â”‚          â•‘
â•‘ â”‚                                                â”‚                               â”‚          â•‘
â•‘ â”‚   Dense(dâ†’2d)                                  â”‚                               â”‚          â•‘
â•‘ â”‚       â”‚                                        â”‚                               â”‚          â•‘
â•‘ â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                               â”‚          â•‘
â•‘ â”‚   content_half   gate_half       â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â”‚              â”‚           â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â–¼              â–¼           â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚  â”‚ Linear   â”‚  â”‚ DLinOSS  â”‚      â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚  â”‚ Attentionâ”‚  â”‚(Oscillatorâ”‚     â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚  â”‚          â”‚  â”‚   SSM)    â”‚     â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â”‚             â”‚            â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚   RMSNorm       RMSNorm          â”‚  â—„â”€â”€ NEW: Stabilize before GLU gating       â”‚          â•‘
â•‘ â”‚       â”‚             â”‚            â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â”‚         sigmoid          â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â”‚             â”‚            â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚       â””â”€â”€â”€â”€â”€â”€âŠ™â”€â”€â”€â”€â”€â”€â”˜  (gate)    â”‚             â”‚                               â”‚          â•‘
â•‘ â”‚              â”‚                   â”‚             â”‚                               â”‚          â•‘
â•‘ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                               â”‚          â•‘
â•‘                â”‚ glu_output                      â”‚                               â”‚          â•‘
â•‘                â”‚                                 â”‚                               â”‚          â•‘
â•‘                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”‚          â•‘
â•‘                â”‚                                 â”‚                               â”‚          â•‘
â•‘                â”‚                                 â–¼                               â”‚          â•‘
â•‘                â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚          â•‘
â•‘                â”‚                    â”‚       InputGate         â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚  Ïƒ(Dense(glu_output))   â”‚                  â”‚          â•‘
â•‘                â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚          â•‘
â•‘                â”‚                                â”‚                                â”‚          â•‘
â•‘                â”‚                                â–¼                                â”‚          â•‘
â•‘                â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚          â•‘
â•‘                â”‚                    â”‚   Local-Sharp Branch    â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚                         â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚   x_norm âŠ™ input_gate   â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚          â†“              â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚     SWAttention         â”‚                  â”‚          â•‘
â•‘                â”‚                    â”‚   (Sliding Window)      â”‚                  â”‚          â•‘
â•‘                â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚          â•‘
â•‘                â”‚                                â”‚                                â”‚          â•‘
â•‘                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚          â•‘
â•‘                             â”‚                                                    â”‚          â•‘
â•‘                             â–¼                                                    â”‚          â•‘
â•‘                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚          â•‘
â•‘                  â”‚  Token-wise Mixing     â”‚                                      â”‚          â•‘
â•‘                  â”‚  Î±_tÂ·GLU + (1-Î±_t)Â·Loc â”‚â—„â”€â”€ Î±_t = Ïƒ(WÎ±Â·h_t + Î±_bias(t))       â”‚          â•‘
â•‘                  â”‚  (per-token mixing)    â”‚    (NEW: position-dependent Î±)       â”‚          â•‘
â•‘                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚          â•‘
â•‘                              â”‚                                                   â”‚          â•‘
â•‘                              â–¼                                                   â”‚          â•‘
â•‘                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚          â•‘
â•‘                  â”‚        Dropout         â”‚                                      â”‚          â•‘
â•‘                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚          â•‘
â•‘                              â”‚                                                   â”‚          â•‘
â•‘                              â–¼                                                   â”‚          â•‘
â•‘                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚          â•‘
â•‘                  â”‚      SwiGLU FFN        â”‚                                      â”‚          â•‘
â•‘                  â”‚  Dense(dâ†’3d/2) â†’ split â”‚                                      â”‚          â•‘
â•‘                  â”‚  swish(a)âŠ™b â†’ Dense    â”‚                                      â”‚          â•‘
â•‘                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚          â•‘
â•‘                              â”‚                                                   â”‚          â•‘
â•‘                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â•‘
â•‘                                                              â”‚ + (residual)                 â•‘
â•‘                                                              â–¼                              â•‘
â•‘                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â•‘
â•‘                                                   â”‚       LayerNorm        â”‚                â•‘
â•‘                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â•‘
â•‘                                                               â”‚                             â•‘
â•‘                                                               â–¼                             â•‘
â•‘                                                            Output                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Key Components

| Component | Description |
|-----------|-------------|
| **DLinOSS** | Damped oscillators with ÏÂ·R(Î¸) rotation, selective Î”t |
| **LinearAttention** | O(L) complexity, ELU+1 feature map |
| **RMSNorm** | Root Mean Square normalization before GLU gating (stabilizes training) |
| **Token-wise Î±** | Per-token mixing: Î±_t = Ïƒ(WÎ±Â·h_t + bias), not sequence-global |
| **SWAttention** | Local window softmax attention with causal masking |

### Training Mode (Text Diffusion)

```
  "The cat sat on mat"                 Fully Masked               Iterative Denoising
          â”‚                                 â”‚                            â”‚
          â–¼                                 â–¼                            â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Forward pass  â”‚   tâ†’1          â”‚ [M] [M] [M] [M] â”‚  tâ†’0     â”‚ Reverse pass  â”‚
  â”‚ (masking)     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ [M]             â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (denoising)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The model follows the **LLaDA** paradigm - a discrete text diffusion model:
1. **Forward**: progressively masks tokens (clean â†’ fully masked)
2. **Reverse**: iteratively predicts and unmasks tokens based on confidence (masked â†’ clean)

### Model Configurations

| Config | vocab | embed_dim | heads | layers | seq_len |
|--------|-------|-----------|-------|--------|---------|
| small | 1000 | 64 | 2 | 2 | 64 |
| default | 32000 | 256 | 4 | 6 | 512 |
| base | 32000 | 512 | 8 | 12 | 512 |
| large | 32000 | 1024 | 16 | 24 | 1024 |
| **production** | 32000 | 768 | 12 | 12 | 1024 |

### Core Innovation

The **OssammaBlock** combines:
- **Global-Spectral**: Linear attention gated by oscillatory SSM (captures long-range patterns)
- **Local-Sharp**: Sliding window softmax attention (captures local precision)
- **Adaptive mixing**: Learns when to use global vs local based on content and diffusion timestep `t`

---

## Current Architecture

### SWAttention (Sliding Window Attention)

**Core Design:**
```
Input (dimension, T)
    â†“
[Q, K, V] Dense Projections (dimension â†’ dimension)
    â†“
Split into H heads (d_k per head, where d_k = dimension / H)
    â†“
Per-head computation:
    - Attention scores: Q' * K / âˆšd_k â†’ (T, T)
    - Normalize with sigmoid instead of softmax
    - Weighted values: V * attention_weights â†’ (d_k, T)
    â†“
Concatenate heads (dimension, T)
    â†“
Output projection (dimension â†’ dimension)
    â†“
Output (dimension, T)
```

**Key Innovation:**
- Uses `normalized_sigmoids` instead of `softmax` for attention weights
- Temperature-scaled sigmoid: `Ïƒ(x/Ï„)` normalized to sum to 1
- Each row of attention matrix is independently normalized

**Current Implementation Details:**
- Stateless layer (no recurrence)
- Requires `dimension % number_of_heads == 0`
- `sequence_length` parameter stored but not enforced
- All projections are same dimension (no bottlenecks)

---

### OSSM (Oscillatory State Space Model)

**Core Design:**
```
Input u (dim_in, T)
    â†“
Input Gating: g_in = Ïƒ(Dense(u))
u_gated = g_in âŠ™ u
    â†“
SSM Processing (for each timestep t):
    State xt: (2H, 1) - H oscillators, 2 coords each

    Selective Step Sizing:
        Î”t = softplus(WÎ” * ut + bÎ”)  â†’ (H,)

    Damped Rotation:
        Ï = exp(-softplus(Î±) * Î”t)   â†’ (H,) damping
        Î¸ = Ï‰ * Î”t                    â†’ (H,) rotation

    State Update:
        x_{t+1} = A(Ï,Î¸) * xt + B * ut
        where A(Ï,Î¸) applies per-oscillator 2D rotation

    Output:
        yt = C * xt + D * ut
    â†“
Collect Y from all timesteps â†’ (dim_out, T)
    â†“
Mixture Gating:
    g_mix = Ïƒ(Dense(u))
    out = g_mix âŠ™ Y + (1 - g_mix) âŠ™ u
    â†“
Output (dim_out, T)
```

**Key Innovations:**
1. **Learnable Oscillators**: Each of H oscillators has independent frequency Ï‰ and damping Î±
2. **Selective Step Sizing**: Step size Î”t depends on input (like Mamba's selective SSM)
3. **Stable Dynamics**: Damping forced positive via softplus ensures Ï âˆˆ (0,1]
4. **Gated Skip Connections**: Both input and output are gated

**State Convention:**
- State is (2H, 1) column vector
- Reshaped to (2, H) for per-oscillator operations
- Each oscillator has 2D state (x, y) representing phase space coordinates

---

## OSSM vs. Mamba Architecture: Detailed Comparison

### Overview

Both OSSM and [Mamba](https://arxiv.org/abs/2312.00752) are selective state space models designed for efficient sequence processing with linear-time complexity. However, they differ fundamentally in their mathematical foundations, state dynamics, and implementation strategies.

### Core Similarities

| Aspect | Both Architectures |
|--------|-------------------|
| **Paradigm** | Selective State Space Models (parameters depend on input) |
| **Complexity** | Linear time O(T) vs. quadratic O(TÂ²) in transformers |
| **Sequential Processing** | Recurrent state updates across time |
| **Input-Dependent Dynamics** | State transitions adapt based on current input |
| **Gating Mechanisms** | Control information flow |

### Fundamental Differences

#### 1. **State Dynamics & Mathematical Foundation**

**OSSM (Oscillatory):**
```
State Update: x_{t+1} = A(Ï, Î¸) * x_t + B * u_t
where A(Ï, Î¸) = block_diag(Ï_1 * R(Î¸_1), ..., Ï_H * R(Î¸_H))
R(Î¸) = [cos(Î¸) -sin(Î¸)]  # 2D rotation matrix
       [sin(Î¸)  cos(Î¸)]

Ï = exp(-Î± * Î”t)  # damping factor âˆˆ (0, 1]
Î¸ = Ï‰ * Î”t        # rotation angle
```

- **Foundation**: Coupled damped harmonic oscillators from physics
- **A Matrix**: Block-diagonal with 2Ã—2 rotation blocks (non-diagonal, non-separable)
- **State Space**: Explicitly 2D phase space per oscillator (position + velocity)
- **Dynamics**: Rotational + damping (spiral trajectories)
- **Interpretability**: Physical meaning (frequency Ï‰, damping Î±, phase)

**Mamba-1 (Selective S6):**
```
State Update: x_{t+1} = AÌ… * x_t + BÌ… * u_t
where AÌ… = exp(Î” * A), BÌ… = (Î” * A)^{-1} * (exp(Î” * A) - I) * Î” * B
A is diagonal (or low-rank + diagonal in S4)

Discretization: Zero-Order Hold (ZOH)
```

- **Foundation**: Continuous-time linear time-invariant (LTI) systems, discretized
- **A Matrix**: Diagonal or structured (HiPPO initialization)
- **State Space**: Abstract N-dimensional latent space
- **Dynamics**: Exponential decay/growth along principal axes
- **Interpretability**: Less direct physical meaning, more learned representations

**Mamba-2 (SSD - State Space Dual):**
```
A = -Î± * I  # scalar times identity (even simpler!)

Structured matrix multiplication formulation
Bridges SSMs and attention via duality
```

- **Foundation**: Structured state space duality theory
- **A Matrix**: Scalar multiple of identity (maximum simplicity)
- **Efficiency**: Leverages matrix multiplication primitives (faster than Mamba-1)

#### 2. **Selective Mechanism (Input-Dependent Parameters)**

**OSSM:**
- **What's Selective**: Step size `Î”t` only
- **How**: `Î”t = softplus(W_Î” * u_t + b_Î”)` â†’ (H,) per oscillator
- **Fixed**: Frequencies `Ï‰`, damping `Î±`, B, C, D (after training)
- **Intuition**: Adapt temporal resolution per oscillator based on input

**Mamba-1:**
- **What's Selective**: `Î”, B, C` (all three!)
- **How**:
  - `Î” = softplus(Linear_Î”(u_t))` â†’ (N,) or (D,)
  - `B = Linear_B(u_t)` â†’ (N,)
  - `C = Linear_C(u_t)` â†’ (N,)
- **Fixed**: A matrix structure (HiPPO initialization)
- **Intuition**: Fully adaptive filtering (what to remember, what to forget, what to output)

**Mamba-2:**
- Similar to Mamba-1 but with simplified A matrix
- Focus on efficient matrix multiplication formulation

#### 3. **State Dimension**

| Model | State Dim | Typical Values | Notes |
|-------|-----------|---------------|-------|
| **OSSM** | 2H | 2Ã—4 = 8 to 2Ã—64 = 128 | Paired (2D per oscillator), grows with H |
| **Mamba-1** | N | 16 (standard) | Fixed per layer, independent of model dim |
| **Mamba-2** | N | 64-256 | Much larger thanks to efficient SSD algorithm |

**Key Insight**: Mamba-2 can use 16Ã— larger state dimension than Mamba-1 while being faster, thanks to the SSD formulation. OSSM's state grows with oscillator count.

#### 4. **Hardware-Aware Implementation**

**OSSM:**
- **Algorithm**: Sequential `foldl` scan over time
- **Parallelism**: None across time (inherently sequential)
- **Memory**: Stores full output buffer Y: (dim_out, T)
- **Optimization Level**: Basic Julia (not hardware-optimized)
- **Speed**: Standard, no special kernels

**Mamba-1:**
- **Algorithm**: [Parallel associative scan](https://github.com/state-spaces/mamba) with kernel fusion
- **Parallelism**: Work-efficient parallel scan O(log T) depth
- **Memory**: Recomputation strategy (don't store intermediate states)
- **Optimization**: Custom CUDA kernels, kernel fusion
- **Speed**: ~40Ã— faster than naive implementation
- **Implementation**: ~3000 lines of optimized CUDA

**Mamba-2:**
- **Algorithm**: Structured matrix multiplication (SSD)
- **Parallelism**: Leverages optimized GEMM primitives
- **Memory**: More memory-efficient than Mamba-1
- **Optimization**: Uses existing optimized BLAS/cuBLAS
- **Speed**: 2-8Ã— faster than Mamba-1 in training
- **Implementation**: ~25 lines of minimal code (much simpler!)

#### 5. **Gating Architecture**

**OSSM:**
```
u_gated = Ïƒ(InputGate(u)) âŠ™ u          # input gating
Y = SSM(u_gated)                        # SSM processing
out = Ïƒ(MixGate(u)) âŠ™ Y + (1-Ïƒ) âŠ™ u    # mixture + residual
```
- **Two gates**: Input gate and mixture gate
- **Explicit skip**: Gated residual connection around SSM
- **Design**: Similar to gated RNNs (GRU-style)

**Mamba:**
```
x_proj = Linear(x)                      # project input
x, gate = split(x_proj)                 # split into data + gate
x_conv = Conv1d(x)                      # short convolution
x_ssm = SSM(x_conv)                     # selective scan
out = x_ssm âŠ™ Ïƒ(gate)                   # gated output
```
- **Single gate**: Output gating only
- **Conv layer**: 1D convolution before SSM (not in OSSM)
- **Design**: Similar to Gated Linear Unit (GLU)

#### 6. **Additional Architectural Components**

| Component | OSSM | Mamba |
|-----------|------|-------|
| **Convolution** | âŒ None | âœ… 1D conv (kernel size 4) |
| **Normalization** | âŒ None (should add) | âœ… RMSNorm |
| **Skip Connections** | âš ï¸ Gated (requires dim match) | âœ… Direct residual |
| **Projection Layers** | âœ… Input/output gates | âœ… Input/output projections |

#### 7. **Theoretical Properties**

**OSSM:**
- **Stability**: Guaranteed stable (Ï < 1 via softplus on Î±)
- **Frequency Selectivity**: Explicit via learnable Ï‰
- **Long-term Memory**: Depends on damping Î± (can decay quickly)
- **Inductive Bias**: Periodic/oscillatory patterns

**Mamba:**
- **Stability**: Depends on A matrix eigenvalues (HiPPO initialization helps)
- **Frequency Selectivity**: Implicit in state space
- **Long-term Memory**: Optimized via HiPPO basis (designed for long sequences)
- **Inductive Bias**: General sequence modeling

#### 8. **Computational Complexity**

For sequence length T, state dimension N/2H, model dimension D:

| Operation | OSSM | Mamba-1 | Mamba-2 |
|-----------|------|---------|---------|
| **Forward Pass** | O(T Â· H) | O(T Â· N) | O(T Â· N) |
| **Scan Algorithm** | O(T) sequential | O(T) parallel | O(T) via matmul |
| **Memory (Training)** | O(T Â· D) | O(1) per stepâ€  | O(T Â· N) |
| **Memory (Inference)** | O(H) state | O(N) state | O(N) state |

â€  Mamba-1 uses selective recomputation to save memory

### Performance Comparison (Estimated)

**Speed (Relative to Mamba-1 = 1.0Ã—):**
- OSSM (current): ~0.02Ã— (40Ã— slower - no parallelism, no kernels)
- Mamba-1 (CUDA): 1.0Ã— (baseline with parallel scan)
- Mamba-2 (SSD): 2-8Ã— (faster via matmul primitives)

**Memory Efficiency:**
- OSSM: Moderate (stores full output, no recomputation)
- Mamba-1: Excellent (selective recomputation)
- Mamba-2: Very good (efficient SSD formulation)

**Long Sequence Performance:**
- OSSM: Untested (likely struggles >10k due to sequential scan)
- Mamba-1: Excellent (tested up to 1M tokens)
- Mamba-2: Excellent (faster than Mamba-1 at all lengths)

### Unique Advantages

**OSSM Advantages:**
1. **Interpretable oscillators**: Clear physical meaning (frequency, damping)
2. **Explicit periodicity**: Built-in bias for periodic patterns
3. **Phase space dynamics**: Rich 2D rotational behavior per oscillator
4. **Simplicity**: Conceptually straightforward (harmonic oscillators)
5. **Multi-scale potential**: Different oscillators for different frequencies

**Mamba Advantages:**
1. **Hardware optimization**: 40-100Ã— faster in practice
2. **Full selectivity**: Adaptive Î”, B, C (not just Î”t)
3. **Proven scaling**: State-of-the-art on language modeling benchmarks
4. **Long-range memory**: HiPPO initialization optimized for recall
5. **Production-ready**: Optimized implementation, extensive testing
6. **Mamba-2 simplicity**: SSD formulation easier to implement and faster

### When to Use Which?

**Use OSSM when:**
- You have strong periodic/oscillatory patterns (audio, circadian rhythms, seasonal data)
- You want interpretable frequency components
- You need explicit multi-scale temporal dynamics
- Working with small to medium sequences (<10k)
- Prototyping research ideas in Julia

**Use Mamba when:**
- You need state-of-the-art performance on language/general sequences
- You require extreme efficiency (long sequences >100k)
- You have GPU resources and need speed
- You want production-ready implementation
- Working with information-dense sequential data

### Hybrid Possibilities

Could combine OSSM's oscillatory dynamics with Mamba's efficiency:
```
OSSM-Mamba Hybrid:
1. Use Mamba's parallel scan algorithm for OSSM's oscillator updates
2. Add OSSM's rotational dynamics to Mamba's state transitions
3. Multi-resolution: Mamba for fast dynamics, OSSM oscillators for slow periodic components
4. Frequency-selective Mamba: Use OSSM's Ï‰ to initialize Mamba's A matrix structure
```

### References

- **Mamba-1**: Gu & Dao, ["Mamba: Linear-Time Sequence Modeling with Selective State Spaces"](https://arxiv.org/abs/2312.00752) (2023)
- **Mamba-2**: Dao & Gu, ["Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality"](https://arxiv.org/abs/2405.21060) (2024)
- **Visual Guide**: [A Visual Guide to Mamba and State Space Models](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state)
- **Implementation**: [GitHub - state-spaces/mamba](https://github.com/state-spaces/mamba)
- **S4 Foundation**: Gu et al., ["Efficiently Modeling Long Sequences with Structured State Spaces"](https://arxiv.org/abs/2111.00396) (2021)

---

## Proposed Architectural Improvements

### SWAttention Improvements

#### 1. **Add Causal Masking Support**
```julia
struct SWAttention <: Lux.AbstractLuxLayer
    # ... existing fields
    causal::Bool  # NEW: enable causal (autoregressive) attention
end
```
**Why**: Essential for autoregressive tasks (language modeling, time series prediction)

#### 2. **Implement Relative Position Bias**
```julia
struct SWAttention <: Lux.AbstractLuxLayer
    # ... existing fields
    use_relative_pos::Bool
    max_distance::Int
end

# In parameters:
relative_pos_bias::Array  # (2*max_distance + 1, number_of_heads)
```
**Why**: Position information crucial for sequence tasks; relative positions generalize better than absolute

#### 3. **Add Attention Dropout**
```julia
# In forward pass after normalized_sigmoids:
if training
    attention_weights = dropout(attention_weights, p=dropout_rate)
end
```
**Why**: Regularization; prevents overfitting to specific attention patterns

#### 4. **Configurable Temperature Learning**
```julia
struct SWAttention <: Lux.AbstractLuxLayer
    # ... existing fields
    learnable_temperature::Bool
end

# In parameters:
Ï„::Vector{Float32}  # per-head or global temperature
```
**Why**: Fixed Ï„=1.0 may be suboptimal; learned temperature can adapt to data

#### 5. **Multi-Query Attention (MQA) / Grouped-Query Attention (GQA)**
```julia
struct SWAttention <: Lux.AbstractLuxLayer
    # ... existing fields
    kv_heads::Int  # number of KV heads (< number_of_heads for MQA/GQA)
end
```
**Why**: Reduces KV cache size for inference; huge memory savings with minimal quality loss

---

### OSSM Improvements

#### 0. **Mamba-Inspired Enhancements** â­

Based on the comparison with Mamba, these improvements would bring OSSM closer to production-ready:

**a) Make B and C Selective (like Mamba):**
```julia
# Current: only Î”t is selective
# Proposed: B, C also input-dependent
function oscillator_step(block, params, xt, ut)
    # Selective parameters
    Î”t = softplus.(params.WÎ” * ut .+ reshape(params.bÎ”, :, 1))  # (H,)
    B_t = params.WB * ut  # (2H, 1) - NEW: input-dependent input mixing
    C_t = params.WC * ut  # (dim_out,) - NEW: input-dependent output mixing

    # State update with selective B
    x_next = apply_oscillation(block, xt, Ï, Î¸) + B_t .* ut

    # Output with selective C
    y = (C_t' .* params.C) * xt + params.D * ut
end
```
**Impact**: Full selectivity like Mamba; more expressive filtering

**b) Add 1D Convolution Before SSM:**
```julia
struct OSSM <: Lux.AbstractLuxLayer
    # ... existing fields
    conv::Lux.Conv  # 1D conv, kernel size 4
end

function (block::OSSM)(u, params, state)
    # Convolve first (local context)
    u_conv = block.conv(u, params.conv, state.conv)
    # Then SSM (global context)
    # ... rest of processing
end
```
**Impact**: Better local context modeling; proven in Mamba

**c) Parallel Scan Implementation:**
```julia
# Replace sequential foldl with parallel associative scan
# Requires: expressing oscillator update as binary associative operator
# Benefit: O(log T) depth vs O(T), much faster on GPU
# Challenge: Non-trivial for 2D rotation matrices (not just element-wise)
```
**Impact**: 10-40Ã— speedup for long sequences (needs GPU kernels)

**d) HiPPO-Inspired Frequency Initialization:**
```julia
function initialize_frequencies_hippo(H::Int)
    # Initialize frequencies to cover spectrum like HiPPO
    # Low frequencies for long-term memory
    Ï‰_low = range(0.01, 0.1, length=HÃ·3)
    Ï‰_mid = range(0.1, 1.0, length=HÃ·3)
    Ï‰_high = range(1.0, 10.0, length=HÃ·3)
    return vcat(Ï‰_low, Ï‰_mid, Ï‰_high)
end
```
**Impact**: Better coverage of timescales; principled initialization

#### 1. **Flexible Skip Connection**
Currently requires `dim_in == dim_out`. Add projection:
```julia
struct OSSM <: Lux.AbstractLuxLayer
    # ... existing fields
    skip_proj::Union{Nothing, Lux.Dense}
end

function OSSM(dim_in, dim_out, H; use_skip_proj=nothing)
    skip_proj = if dim_in != dim_out
        use_skip_proj === false ? nothing : Lux.Dense(dim_in => dim_out)
    else
        nothing
    end
    # ...
end
```
**Why**: Removes dimension constraint; more flexible architecture composition

#### 2. **Multi-Scale Oscillators**
```julia
struct OSSM <: Lux.AbstractLuxLayer
    # ... existing fields
    frequency_bands::Vector{Tuple{Float32, Float32}}  # (Ï‰_min, Ï‰_max) per band
end
```
Initialize different oscillator groups with different frequency ranges:
- Low freq: Ï‰ âˆˆ [0.01, 0.1] - long-term patterns
- Mid freq: Ï‰ âˆˆ [0.1, 1.0] - medium-term
- High freq: Ï‰ âˆˆ [1.0, 10.0] - short-term

**Why**: Captures patterns at multiple timescales explicitly

#### 3. **Learnable Initial State**
```julia
# In parameters:
x0::Array{Float32, 2}  # (2H, 1) learnable initial state

# In initialstates:
(; oscillation_state = copy(params.x0))
```
**Why**: Better than zero initialization; can encode prior knowledge about typical dynamics

#### 4. **Residual Oscillator Connections**
```julia
# In apply_oscillation:
x_next = Ï .* rotate(x) + (1 .- Ï) .* x_identity + B * ut
```
Add identity skip within oscillators (not just around the whole OSSM)

**Why**: Helps gradient flow; prevents oscillators from collapsing

#### 5. **Normalization Layers**
```julia
struct OSSM <: Lux.AbstractLuxLayer
    # ... existing fields
    norm_input::Union{Nothing, Lux.LayerNorm}
    norm_output::Union{Nothing, Lux.LayerNorm}
end
```
**Why**: Stabilizes training; standard practice in modern architectures

---

## Code-Level Improvements

### Performance Optimizations

#### 1. **Preallocate Rotation Matrices** (OSSM)
Current code allocates rotation matrix per oscillator in comprehension:
```julia
# Current (allocates H rotation matrices):
cols = [Ïi * [cos(Î¸i) -sin(Î¸i); sin(Î¸i) cos(Î¸i)] * xi for ...]

# Improved (vectorized):
function apply_oscillation_vectorized(block, x, Ï, Î¸)
    x_view = reshape(x, 2, :)  # (2, H)
    cos_Î¸ = cos.(Î¸)'  # (1, H)
    sin_Î¸ = sin.(Î¸)'  # (1, H)

    # Vectorized rotation
    x1, x2 = x_view[1, :], x_view[2, :]
    x1_new = Ï .* (cos_Î¸ .* x1 - sin_Î¸ .* x2)
    x2_new = Ï .* (sin_Î¸ .* x1 + cos_Î¸ .* x2)

    return vcat(x1_new', x2_new')[:, 1:1]  # reshape to (2H, 1)
end
```
**Impact**: Reduces allocations; ~2-3x faster for large H

#### 2. **Fused Attention Computation** (SWAttention)
```julia
# Current: Multiple intermediate allocations
# Improved: Use BLAS operations directly
function compute_attention(q, k, v, d_k)
    # q, k, v: (d_k, T)
    scores = BLAS.gemm('T', 'N', 1.0/âˆšd_k, q, k)  # (T, T) - fused transpose
    # ... normalize ...
    output = BLAS.gemm('N', 'N', 1.0, v, weights)  # (d_k, T)
end
```
**Impact**: Fewer allocations; better cache locality

#### 3. **In-place Operations**
```julia
# In OSSM forward pass, reuse buffer:
function (block::OSSM)(u, params, state)
    # ...
    Y = similar(u, block.dim_out, T)

    # Current allocates g_in .* u
    # Improved:
    u_gated = similar(u)
    u_gated .= g_in .* u  # in-place

    # Similarly for final output:
    out = similar(Y)
    out .= g_mix .* Y .+ (oneT .- g_mix) .* u
end
```
**Impact**: Reduces GC pressure; important for large batches

### Code Quality Improvements

#### 1. **Add Input Validation**
```julia
function (block::SWAttention)(x, params, state)
    @assert size(x, 1) == block.dimension "Input dimension mismatch"
    @assert ndims(x) == 2 "Expected 2D input (dimension, T)"
    # ...
end

function (block::OSSM)(u, params, state)
    @assert size(u, 1) == block.dim_in "Input dimension mismatch"
    @assert ndims(u) == 2 "Expected 2D input (dim_in, T)"
    # ...
end
```
**Why**: Better error messages; easier debugging

#### 2. **Separate Concerns - Extract Helper Modules**
```julia
# Create src/utils/attention_ops.jl
module AttentionOps
    export normalized_sigmoids, compute_attention_scores
    # ... attention utilities
end

# Create src/utils/oscillator_ops.jl
module OscillatorOps
    export apply_oscillation, make_rotation_matrix
    # ... oscillator utilities
end
```
**Why**: Better organization; reusable components; easier testing

#### 3. **Add Type Stability Checks**
```julia
# Use @code_warntype to check type stability
# Add explicit type annotations where needed:

function oscillator_step(block, params, xt::Matrix{T}, ut::Matrix{T}) where T
    # ...
    Î”t = NNlib.softplus.(WÎ” * ut .+ reshape(bÎ”, :, 1))::Matrix{T}
    # ...
end
```
**Why**: Type stability crucial for Julia performance

#### 4. **Configuration Struct Pattern**
```julia
@kwdef struct SWAttentionConfig
    dimension::Int
    number_of_heads::Int
    sequence_length::Int = 1024
    dropout::Float32 = 0.0f0
    causal::Bool = false
    use_relative_pos::Bool = false
    learnable_temperature::Bool = false
end

function SWAttention(config::SWAttentionConfig)
    # construct from config
end
```
**Why**: Easier to manage many hyperparameters; better for experiments

#### 5. **Add Comprehensive Tests**
```julia
# test/test_attention.jl
@testset "SWAttention" begin
    @testset "Dimension checks" begin
        # test dimension compatibility
    end

    @testset "Gradient flow" begin
        # test backpropagation works
    end

    @testset "Causality" begin
        # test causal masking if implemented
    end
end

# test/test_ossm.jl
@testset "OSSM" begin
    @testset "State evolution" begin
        # test state updates correctly
    end

    @testset "Oscillator stability" begin
        # test Ï âˆˆ (0, 1], no NaN/Inf
    end

    @testset "Selective stepping" begin
        # test Î”t > 0 always
    end
end
```

#### 6. **Add Docstrings**
```julia
"""
    SWAttention(sequence_length, dimension, number_of_heads)

Sliding Window Attention with normalized sigmoid activation.

Uses temperature-scaled sigmoid normalization instead of softmax for computing
attention weights. Each attention head operates on dimension/number_of_heads features.

# Arguments
- `sequence_length::Int`: Maximum sequence length (stored but not enforced)
- `dimension::Int`: Embedding dimension (must be divisible by number_of_heads)
- `number_of_heads::Int`: Number of parallel attention heads

# Returns
- `SWAttention` layer instance

# Example
```julia
using Lux, Random
attn = SWAttention(1024, 128, 4)
rng = Random.default_rng()
ps = Lux.initialparameters(rng, attn)
st = Lux.initialstates(rng, attn)
x = randn(Float32, 128, 64)  # (dimension, batch_size)
y, _ = attn(x, ps, st)  # (128, 64)
```
"""
function SWAttention(sequence_length::Int, dimension::Int, number_of_heads::Int)
    # ...
end
```

---

## Integration Suggestions

### Combining SWAttention + OSSM

Create a hybrid architecture:
```julia
struct SambaBlock <: Lux.AbstractLuxLayer
    attention::SWAttention
    ssm::OSSM
    mix_gate::Lux.Dense
    norm1::Lux.LayerNorm
    norm2::Lux.LayerNorm
end

function (block::SambaBlock)(x, params, state)
    # Parallel paths:
    # 1. Attention path
    x_norm1 = block.norm1(x, params.norm1, state.norm1)
    attn_out, st_attn = block.attention(x_norm1, params.attention, state.attention)

    # 2. SSM path
    x_norm2 = block.norm2(x, params.norm2, state.norm2)
    ssm_out, st_ssm = block.ssm(x_norm2, params.ssm, state.ssm)

    # 3. Gated mixing
    gate = block.mix_gate(x, params.mix_gate, state.mix_gate)
    out = gate .* attn_out + (1 .- gate) .* ssm_out + x  # residual

    return out, (attention=st_attn, ssm=st_ssm, ...)
end
```

**Why**: Combines global attention with local SSM dynamics; attention for long-range, SSM for sequential

---

## Priority Recommendations

### Immediate (High Impact, Low Effort)
1. âœ… **Add skip projection to OSSM** - removes `dim_in == dim_out` constraint
2. âœ… **Vectorize oscillator rotation** - 2-3Ã— speedup, straightforward
3. âœ… **Add input validation** - better error messages, easy to add
4. âœ… **Write basic tests** - ensure correctness, prevent regressions

### Short-Term (High Impact, Medium Effort)
5. ğŸ¯ **Add 1D convolution to OSSM** - proven in Mamba, local context
6. ğŸ¯ **Add normalization to OSSM** - training stability (RMSNorm or LayerNorm)
7. ğŸ¯ **Add causal masking to SWAttention** - enables autoregressive tasks
8. ğŸ¯ **Implement attention dropout** - regularization
9. ğŸ¯ **Add docstrings** - usability, easier onboarding

### Medium-Term (Mamba-Inspired, Higher Effort)
10. ğŸ”¬ **Make B and C selective in OSSM** - full selectivity like Mamba
11. ğŸ”¬ **HiPPO frequency initialization** - principled multi-scale coverage
12. ğŸ”¬ **Learnable initial state** - better than zero init
13. ğŸ”¬ **Multi-scale oscillator groups** - explicit frequency bands

### Long-Term (Research & Optimization)
14. ğŸš€ **Parallel associative scan** - 10-40Ã— speedup (needs GPU kernels)
15. ğŸš€ **Hybrid OSSM-Mamba architecture** - combine strengths
16. ğŸš€ **MQA/GQA attention variants** - efficient inference
17. ğŸš€ **Learnable temperature in attention** - adaptive scaling
18. ğŸš€ **SambaBlock** (Attention + OSSM fusion) - explore combinations

### Impact Summary

**Biggest Performance Gains:**
- Vectorize oscillator rotation: ~3Ã— speedup (easy)
- Parallel scan: ~40Ã— speedup (hard, needs CUDA)
- 1D convolution: better accuracy (medium)

**Biggest Capability Gains:**
- Selective B, C: matches Mamba expressiveness
- Causal masking: enables language modeling
- Skip projection: architectural flexibility

**Best Quick Wins (do first):**
1. Skip projection (30 min)
2. Vectorize oscillators (1 hour)
3. Input validation (30 min)
4. Basic tests (2 hours)
5. 1D convolution (1-2 hours)

---

## References & Inspirations

### Key Papers

**State Space Models:**
- **S4**: Gu et al., ["Efficiently Modeling Long Sequences with Structured State Spaces"](https://arxiv.org/abs/2111.00396) (ICLR 2022)
- **Mamba-1**: Gu & Dao, ["Mamba: Linear-Time Sequence Modeling with Selective State Spaces"](https://arxiv.org/abs/2312.00752) (2023)
- **Mamba-2**: Dao & Gu, ["Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality"](https://arxiv.org/abs/2405.21060) (2024)

**Attention Mechanisms:**
- Vaswani et al., ["Attention is All You Need"](https://arxiv.org/abs/1706.03762) (NeurIPS 2017)
- Katharopoulos et al., ["Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"](https://arxiv.org/abs/2006.16236) (ICML 2020)

### Educational Resources

- [A Visual Guide to Mamba and State Space Models](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state) - Excellent visual introduction
- [Mamba Explained | The Gradient](https://thegradient.pub/mamba-explained/) - In-depth technical explanation
- [State Space Duality (Mamba-2) | Goomba Lab](https://goombalab.github.io/blog/2024/mamba2-part1-model/) - Mamba-2 deep dive
- [What Is A Mamba Model? | IBM](https://www.ibm.com/think/topics/mamba-model) - High-level overview

### Implementations

- [GitHub: state-spaces/mamba](https://github.com/state-spaces/mamba) - Official Mamba implementation (PyTorch + CUDA)
- [Lux.jl Documentation](https://lux.csail.mit.edu/) - Julia deep learning framework used in this project

### Neuroscience & Physics Inspirations

**OSSM:**
- Oscillatory networks from computational neuroscience
- Coupled harmonic oscillators from classical mechanics
- Phase space dynamics and limit cycles

### Potential Applications

**OSSM-specific:**
- Time series forecasting (explicit periodicity via oscillators)
- Audio/speech processing (multi-frequency decomposition)
- Circadian rhythm modeling (biological oscillations)
- Seasonal pattern detection (economic, climate data)
- Signal processing (Fourier-like learnable basis)

**General (SSM + Attention):**
- Long sequence modeling (genomics, long-form text)
- Efficient transformers (linear complexity alternative)
- Multimodal learning (audio, video, text)

---

## OssammaMLM: Triple Hybrid Architecture with Mask-Predict

### Overview

OssammaMLM combines three complementary mechanisms with discrete diffusion (mask-predict) training for an efficient LLM alternative.

**Design Goals:**
- Linear complexity O(n) for large context windows
- Expressivity via multiple complementary mechanisms
- Iterative refinement through partial mask/unmask (discrete diffusion)
- **Semantic understanding** - learned relationships, not fixed transforms

### Design Philosophy: Smart LLM, Not Signal Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KEY INSIGHT: For language, we need LEARNED relationships      â”‚
â”‚                                                                 â”‚
â”‚  "The cat sat on the mat"                                      â”‚
â”‚       â†‘         â†‘                                               â”‚
â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                               â”‚
â”‚            â”‚                                                    â”‚
â”‚   Relationship is SEMANTIC (subject-verb), not frequency-based â”‚
â”‚                                                                 â”‚
â”‚   âœ— FNet (FFT) - fixed transform, no semantic learning         â”‚
â”‚   âœ“ Cosformer  - learned Q/K/V, captures meaning               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Three Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Cosformer (Global Learned Attention) - O(n)                â”‚
â”‚                                                                 â”‚
â”‚     "What tokens relate SEMANTICALLY?"                         â”‚
â”‚                                                                 â”‚
â”‚     - Learned Q/K/V projections (not fixed like FFT)           â”‚
â”‚     - Linear attention via kernel decomposition                â”‚
â”‚     - cos/sin reweighting for position awareness               â”‚
â”‚     - Captures long-range semantic dependencies                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. DLinOSS (Damped Linear Oscillatory SSM) - O(n)             â”‚
â”‚                                                                 â”‚
â”‚     "What's the narrative state? What patterns over time?"     â”‚
â”‚                                                                 â”‚
â”‚     - Stateful - carries context across sequence               â”‚
â”‚     - Physics-based temporal memory (spring-damper dynamics)   â”‚
â”‚     - Tracks "the story so far" in oscillator state            â”‚
â”‚     - Multi-frequency response to different pattern timescales â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. SWAttention (Sliding Window Attention) - O(nÂ·w)            â”‚
â”‚                                                                 â”‚
â”‚     "What are the PRECISE local relationships?"                â”‚
â”‚                                                                 â”‚
â”‚     - Hard window for exact neighbor attention                 â”‚
â”‚     - Sigsoftmax for sharper attention patterns                â”‚
â”‚     - Captures syntax, grammar, local coherence                â”‚
â”‚     - "the [adjective] [noun]" - precise local structure       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why NOT FNet for LLMs?

| Aspect | FNet | Cosformer |
|--------|------|-----------|
| **Transform** | Fixed (FFT) | Learned (Q/K/V) |
| **Semantics** | None - frequency mixing | Yes - learns what to attend to |
| **Relationships** | Based on position frequency | Based on meaning |
| **Best for** | Signals, audio, time series | Language, semantics |
| **For Smart LLM** | âœ— Not appropriate | âœ“ Designed for this |

FNet is elegant for signal processing where frequency matters. But language understanding requires **learned semantic relationships** - that's what Cosformer provides.

### Gating Strategy

**Key Insight:** Use GLU-style gating for similar mechanisms, mixture gating for different ones.

```
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Similarity Principle               â”‚
                     â”‚                                     â”‚
                     â”‚  Cosformer â†â”€â”€â†’ DLinOSS            â”‚
                     â”‚  (both O(n), both recurrent-form)   â”‚
                     â”‚  â†’ GLU-style gating                 â”‚
                     â”‚                                     â”‚
                     â”‚  (Cos+DLIN) â†â”€â”€â†’ SWAttention       â”‚
                     â”‚  (different mechanisms)             â”‚
                     â”‚  â†’ Mixture gating                   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Full Forward Pass

```
Input: x (Features, SeqLen, Batch)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DOUBLE PROJECTION (not split - each sees full input)         â”‚
â”‚                                                                  â”‚
â”‚    x â”€â”€â”¬â”€â”€â†’ W_cosformer â”€â”€â†’ x_cos                               â”‚
â”‚        â”‚                                                         â”‚
â”‚        â”œâ”€â”€â†’ W_dlinoss â”€â”€â”€â”€â†’ x_dlin                              â”‚
â”‚        â”‚                                                         â”‚
â”‚        â””â”€â”€â†’ W_attention â”€â”€â†’ x_attn                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PARALLEL PROCESSING                                           â”‚
â”‚                                                                  â”‚
â”‚    x_cos  â”€â”€â†’ Cosformer â”€â”€â”€â”€â†’ y_cos      (O(n), global)         â”‚
â”‚                                                                  â”‚
â”‚    x_dlin â”€â”€â†’ DLinOSS â”€â”€â”€â”€â”€â”€â†’ y_dlin     (O(n), stateful)       â”‚
â”‚                                                                  â”‚
â”‚    x_attn â”€â”€â†’ SWAttention â”€â”€â†’ y_attn     (O(nÂ·w), local)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GLU GATE (Cosformer + DLinOSS - similar mechanisms)          â”‚
â”‚                                                                  â”‚
â”‚    y_linear = y_cos âŠ™ Ïƒ(y_dlin)                                 â”‚
â”‚                                                                  â”‚
â”‚    Intuition: DLinOSS temporal state gates what global          â”‚
â”‚               information from Cosformer passes through         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MIXTURE GATE (Linear + Attention - different mechanisms)     â”‚
â”‚                                                                  â”‚
â”‚    g = Ïƒ(W_mix Â· x + b_mix)     # learned, input-dependent      â”‚
â”‚                                                                  â”‚
â”‚    y_combined = g âŠ™ y_linear + (1 - g) âŠ™ y_attn                 â”‚
â”‚                                                                  â”‚
â”‚    Intuition: Model learns when to use global-linear            â”‚
â”‚               vs local-precise processing                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. OUTPUT HEADS                                                  â”‚
â”‚                                                                  â”‚
â”‚    logits     = unmask_head(y_combined)    # â†’ vocab_size       â”‚
â”‚    confidence = Ïƒ(confidence_head(y_combined))  # â†’ scalar      â”‚
â”‚                                                                  â”‚
â”‚    confidence helps decide which tokens to unmask               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output: (logits, confidence), new_state
```

### Why This Gating Makes Sense

| Gate Type | Components | Reasoning |
|-----------|------------|-----------|
| **GLU** | Cosformer + DLinOSS | Both O(n), both have recurrent interpretations. One naturally modulates the other. |
| **Mixture** | GLU_output + SWAttention | Fundamentally different operations. Model should learn when each is useful. |

**GLU is wrong when:**
- Components do fundamentally different things
- One component's output doesn't naturally "gate" the other
- You need both outputs to contribute information (not just modulate)

**Mixture is wrong when:**
- Components are so similar that gating makes more sense
- You want multiplicative interaction (GLU) not additive mixing

### Mask-Predict Training (Discrete Diffusion)

#### Training Phase

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training Step                                                  â”‚
â”‚                                                                â”‚
â”‚ 1. Full sequence:    [The] [cat] [sat] [on] [the] [mat]       â”‚
â”‚                                                                â”‚
â”‚ 2. Random mask:      [The] [MASK] [sat] [MASK] [the] [MASK]   â”‚
â”‚    (e.g., 40%)                                                 â”‚
â”‚                                                                â”‚
â”‚ 3. Forward pass  â†’  predict all [MASK] positions              â”‚
â”‚                                                                â”‚
â”‚ 4. Loss = CrossEntropy(predictions, targets)                  â”‚
â”‚           only on masked positions                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Mask ratio strategies:**
- Fixed: 15% (BERT-style) or 40-50% (more generative)
- Curriculum: Start easy (15%) â†’ increase to hard (50%+)
- Random: Sample mask ratio uniformly each batch

#### Inference Phase (Iterative Unmasking)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Iterative Unmasking (K steps)                                  â”‚
â”‚                                                                â”‚
â”‚ Step 0: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]             â”‚
â”‚         (fully masked or partially prompted)                   â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼ forward pass                                 â”‚
â”‚         predictions: [The:0.9] [dog:0.3] [sat:0.8] ...        â”‚
â”‚         confidence:  [0.95]    [0.40]    [0.88]   ...         â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼ unmask top-k confident                       â”‚
â”‚                                                                â”‚
â”‚ Step 1: [The] [MASK] [sat] [MASK] [the] [MASK]                â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼ forward pass (refined context!)              â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼ unmask top-k confident                       â”‚
â”‚                                                                â”‚
â”‚ Step 2: [The] [MASK] [sat] [on] [the] [MASK]                  â”‚
â”‚                 â”‚                                              â”‚
â”‚                 â–¼ ...                                          â”‚
â”‚                                                                â”‚
â”‚ Step K: [The] [cat] [sat] [on] [the] [mat]  âœ“ done            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key insight:** Each step has more context â†’ better predictions â†’ iterative refinement

#### Why Mask-Predict + This Architecture?

| Component | Role in Mask-Predict |
|-----------|---------------------|
| **Cosformer** | Aggregate global context from revealed tokens efficiently |
| **DLinOSS** | Track "state of knowledge" as tokens are progressively revealed |
| **SWAttention** | Ensure local coherence between adjacent revealed tokens |
| **confidence_head** | Decide which predictions are reliable enough to commit |

### Struct Definition (Julia/Lux)

```julia
struct OssammaMLM <: Lux.AbstractLuxLayer
    # Dimensions
    input_dim::Int
    hidden_dim::Int
    vocab_size::Int

    # Input projections (double projection - each sees full input)
    proj_cosformer::Lux.Dense    # input_dim â†’ hidden_dim
    proj_dlinoss::Lux.Dense      # input_dim â†’ hidden_dim
    proj_attention::Lux.Dense    # input_dim â†’ hidden_dim

    # Core components
    cosformer::Cosformer         # O(n) global linear attention
    dlinoss::DLinOSS             # O(n) oscillatory SSM
    swattention::SWAttention     # O(nÂ·w) local attention

    # Gating
    mixture_gate::Lux.Dense      # hidden_dim â†’ hidden_dim (for sigmoid)

    # Output heads
    unmask_head::Lux.Dense       # hidden_dim â†’ vocab_size
    confidence_head::Lux.Dense   # hidden_dim â†’ 1
end
```

### Cosformer: Linear Attention with cos/sin Reweighting

#### The Problem with Standard Attention

```
Standard:  Attention(Q,K,V) = softmax(QK^T / âˆšd) Â· V

           QK^T is (SeqLen Ã— SeqLen) â†’ O(nÂ²) memory and compute
```

#### Cosformer Solution

```
Key insight: softmax(QK^T) â‰ˆ Ï†(Q) Â· Ï†(K)^T  for some kernel Ï†

Cosformer uses:
    Ï†(x) = ReLU(x) âŠ™ cos(Ï€Â·pos / 2Â·max_pos)

Then:
    Attention(Q,K,V) = Ï†(Q) Â· (Ï†(K)^T Â· V) / (Ï†(Q) Â· Ï†(K)^T Â· 1)
                       \_____/  \________/
                       (d Ã— n)   (n Ã— d)
                              â†“
                           (d Ã— d) intermediate!

    This is O(n) instead of O(nÂ²)
```

#### Why cos/sin Reweighting?

```
Position 0:   cos(0) = 1.0      (full weight)
Position T/4: cos(Ï€/4) â‰ˆ 0.71
Position T/2: cos(Ï€/2) = 0.0    (zero weight)

Creates position-dependent decay: nearby positions contribute more
Without explicit position encodings!
```

#### Cosformer Struct (Conceptual)

```julia
struct Cosformer <: Lux.AbstractLuxLayer
    dim::Int
    num_heads::Int
    head_dim::Int
    max_seq_len::Int

    # Projections
    query_proj::Lux.Dense
    key_proj::Lux.Dense
    value_proj::Lux.Dense
    output_proj::Lux.Dense
end

# Key operation: linear attention with cos reweighting
function linear_attention(Q, K, V, cos_weights)
    # Apply ReLU and cos reweighting
    Q_prime = relu.(Q) .* cos_weights  # (head_dim, seq_len)
    K_prime = relu.(K) .* cos_weights  # (head_dim, seq_len)

    # Compute in O(n): Ï†(Q) Â· (Ï†(K)^T Â· V)
    KV = K_prime * V'                   # (head_dim, head_dim)
    QKV = Q_prime' * KV                 # (seq_len, head_dim)

    # Normalize
    K_sum = sum(K_prime, dims=2)        # (head_dim, 1)
    normalizer = Q_prime' * K_sum       # (seq_len, 1)

    return QKV ./ (normalizer .+ Îµ)
end
```

### Training Details

#### Loss Function

```
L_total = L_mlm + Î» Â· L_confidence

where:
    L_mlm = CrossEntropy(predicted_tokens, true_tokens)
            # only on masked positions

    L_confidence = BinaryCrossEntropy(confidence, was_correct)
            # calibration: high confidence should mean correct
```

#### Hyperparameters

| Parameter | Typical Range | Notes |
|-----------|---------------|-------|
| `mask_ratio` | 0.15 - 0.50 | Higher = harder, more generative |
| `num_unmasking_steps` | 4 - 12 | More = better quality, slower |
| `unmask_per_step` | 1/num_steps | Fraction to reveal each iteration |
| `temperature` | 0.7 - 1.0 | For sampling during inference |
| `confidence_threshold` | 0.8 - 0.95 | Minimum confidence to unmask |

#### Curriculum Learning (Optional)

```
Epoch 1-10:   mask_ratio = 0.15   # Easy (BERT-style)
Epoch 11-20:  mask_ratio = 0.30   # Medium
Epoch 21-30:  mask_ratio = 0.50   # Hard
Epoch 31+:    mask_ratio ~ U(0.15, 0.60)  # Random for robustness
```

### Comparison: AR vs Mask-Predict

| Aspect | Autoregressive (GPT) | Mask-Predict (OssammaMLM) |
|--------|---------------------|--------------------------|
| **Generation** | Left-to-right, one token at a time | Parallel, iterative refinement |
| **Speed** | O(n) sequential steps | O(K) steps where K << n |
| **Can fix mistakes?** | No (committed once generated) | Yes (iterative refinement) |
| **Bidirectional context?** | No (only left context) | Yes (sees all revealed tokens) |
| **Variable compute?** | No (always n steps) | Yes (more steps = better) |

### Architecture Synergy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Why These Three?                           â”‚
â”‚                                                               â”‚
â”‚  Challenge              Component         How it Helps        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Long-range deps        Cosformer         O(n) global mixing  â”‚
â”‚                                                               â”‚
â”‚  Sequential patterns    DLinOSS           Stateful oscillator â”‚
â”‚                                           memory              â”‚
â”‚                                                               â”‚
â”‚  Local coherence        SWAttention       Precise local       â”‚
â”‚                                           attention           â”‚
â”‚                                                               â”‚
â”‚  Iterative refinement   Mask-Predict      Progressive         â”‚
â”‚                                           unmasking           â”‚
â”‚                                                               â”‚
â”‚  Flexible compute       confidence_head   Variable steps      â”‚
â”‚                                           based on certainty  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation Roadmap

```
Phase 1: Core Components
â”œâ”€â”€ [ ] Implement Cosformer (linear attention)
â”œâ”€â”€ [ ] Wire existing DLinOSS
â”œâ”€â”€ [ ] Wire existing SWAttention
â””â”€â”€ [ ] Verify each component works standalone

Phase 2: OssammaMLM Layer
â”œâ”€â”€ [ ] Create OssammaMLM struct
â”œâ”€â”€ [ ] Implement double projection
â”œâ”€â”€ [ ] Implement GLU gate (Cos + DLIN)
â”œâ”€â”€ [ ] Implement mixture gate (Linear + Attn)
â””â”€â”€ [ ] Add output heads (unmask + confidence)

Phase 3: Mask-Predict Training
â”œâ”€â”€ [ ] Implement masking utilities
â”œâ”€â”€ [ ] Implement MLM loss (masked positions only)
â”œâ”€â”€ [ ] Implement confidence loss
â””â”€â”€ [ ] Training loop with curriculum

Phase 4: Inference
â”œâ”€â”€ [ ] Implement iterative unmasking loop
â”œâ”€â”€ [ ] Add temperature sampling
â”œâ”€â”€ [ ] Add confidence thresholding
â””â”€â”€ [ ] Benchmark generation quality vs speed
```

---

## Alternative: FNet-Style Global Mixing

### Why Consider FNet Over Cosformer?

FNet (Google, 2021) replaces attention entirely with Fourier transforms. For OssammaMLM, this creates an elegant synergy with DLinOSS.

### FNet vs Cosformer Comparison

| Aspect | Cosformer | FNet |
|--------|-----------|------|
| **Mechanism** | Linear attention + cos/sin | Pure FFT |
| **Complexity** | O(n) | O(n log n) |
| **Learnable mixing** | Yes (Q/K/V) | No (fixed FFT) |
| **Parameters** | ~4 Ã— dÂ² | 0 (or minimal) |
| **Expressivity** | Higher | Lower |
| **Speed** | Fast | Faster |

### The Frequency-Domain Synergy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Why FNet + DLinOSS Works                       â”‚
â”‚                                                                 â”‚
â”‚  FNet:    "What frequencies are present in the input?"          â”‚
â”‚           Static decomposition via FFT                          â”‚
â”‚                                                                 â”‚
â”‚  DLinOSS: "How should I respond to each frequency over time?"   â”‚
â”‚           Dynamic filtering via learned oscillators             â”‚
â”‚                                                                 â”‚
â”‚  Together: Analysis (FNet) â†’ Filtering (DLinOSS)                â”‚
â”‚            Both speak "frequency language"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FNet Mixer Implementation

```julia
struct FNetMixer <: Lux.AbstractLuxLayer
    dim::Int
    use_freq_weights::Bool  # learnable frequency modulation
end

function FNetMixer(dim::Int; use_freq_weights::Bool = true)
    return FNetMixer(dim, use_freq_weights)
end

function Lux.initialparameters(rng::Random.AbstractRNG, layer::FNetMixer)
    if layer.use_freq_weights
        # Learnable per-frequency weights (complex or real)
        return (freq_weights = ones(Float32, layer.dim),)
    else
        return (;)  # no parameters
    end
end

function Lux.initialstates(rng::Random.AbstractRNG, layer::FNetMixer)
    return (;)  # stateless
end

function (layer::FNetMixer)(x, params, state)
    # x: (features, seq_len, batch) or (features, seq_len)

    # 1. FFT along sequence dimension (dim 2)
    x_fft = fft(x, 2)

    # 2. Optional: learnable frequency modulation
    if layer.use_freq_weights
        # Broadcast weights across sequence positions
        x_fft = x_fft .* reshape(params.freq_weights, :, 1, 1)
    end

    # 3. IFFT back to sequence domain
    x_mixed = real(ifft(x_fft, 2))

    return x_mixed, state
end
```

### FNet Variants

#### 1. Pure FNet (Original)
```
x â†’ FFT â†’ IFFT â†’ output
```
- No learnable parameters in mixing
- Simplest, fastest
- 92-97% of BERT performance

#### 2. FNet + Frequency Weights
```
x â†’ FFT â†’ W_freq âŠ™ X_fft â†’ IFFT â†’ output
```
- Learnable per-frequency scaling
- Allows model to emphasize/suppress certain frequencies
- Minimal parameter overhead

#### 3. FNet + Frequency MLP
```
x â†’ FFT â†’ MLP(X_fft) â†’ IFFT â†’ output
```
- Full learnable transform in frequency domain
- More expressive, more parameters
- Still O(n log n)

#### 4. Hybrid: FNet + Sparse Attention
```
x â†’ FNet (global) + SWAttention (local) â†’ gated combine
```
- FNet handles global mixing cheaply
- Attention only for local precision
- Best of both worlds

### Updated OssammaMLM with FNet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OssammaMLM (FNet Variant)                                         â”‚
â”‚                                                                  â”‚
â”‚ Input: x (Features, SeqLen, Batch)                               â”‚
â”‚                                                                  â”‚
â”‚ 1. PROJECTIONS                                                   â”‚
â”‚    x â”€â”€â”¬â”€â”€â†’ W_fnet â”€â”€â”€â”€â†’ x_fnet     (or skip if pure FNet)      â”‚
â”‚        â”œâ”€â”€â†’ W_dlinoss â”€â”€â†’ x_dlin                                â”‚
â”‚        â””â”€â”€â†’ W_attention â†’ x_attn                                â”‚
â”‚                                                                  â”‚
â”‚ 2. PARALLEL PROCESSING                                           â”‚
â”‚    x_fnet â”€â”€â†’ FNetMixer â”€â”€â”€â†’ y_fft    (O(n log n), global)      â”‚
â”‚    x_dlin â”€â”€â†’ DLinOSS â”€â”€â”€â”€â”€â†’ y_dlin   (O(n), temporal)          â”‚
â”‚    x_attn â”€â”€â†’ SWAttention â”€â†’ y_attn   (O(nÂ·w), local)           â”‚
â”‚                                                                  â”‚
â”‚ 3. GLU GATE (FNet + DLinOSS)                                    â”‚
â”‚    y_freq = y_fft âŠ™ Ïƒ(y_dlin)                                   â”‚
â”‚                                                                  â”‚
â”‚    â†‘ Both in frequency domain - natural pairing!                â”‚
â”‚                                                                  â”‚
â”‚ 4. MIXTURE GATE                                                  â”‚
â”‚    g = Ïƒ(W_mix Â· x)                                             â”‚
â”‚    y_combined = g âŠ™ y_freq + (1-g) âŠ™ y_attn                     â”‚
â”‚                                                                  â”‚
â”‚ 5. OUTPUT HEADS                                                  â”‚
â”‚    logits = unmask_head(y_combined)                             â”‚
â”‚    confidence = Ïƒ(confidence_head(y_combined))                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why GLU Makes Even More Sense Now

With Cosformer + DLinOSS, GLU worked because both were O(n) and had recurrent forms.

With FNet + DLinOSS, GLU is **even more natural**:

```
FNet output:   Frequency-decomposed representation
               "Here are the frequency components"

DLinOSS output: Oscillator responses (Ïƒ applied)
                "Here's how important each frequency is right now"

GLU combination: FNet âŠ™ Ïƒ(DLinOSS)
                 "Pass frequencies that matter, gate others"
```

This is essentially **learned frequency-domain gating**.

### Struct Definition (FNet Variant)

```julia
struct OssammaMLM_FNet <: Lux.AbstractLuxLayer
    # Dimensions
    input_dim::Int
    hidden_dim::Int
    vocab_size::Int

    # Input projections
    proj_fnet::Lux.Dense        # optional, can skip for pure FNet
    proj_dlinoss::Lux.Dense
    proj_attention::Lux.Dense

    # Core components
    fnet::FNetMixer             # O(n log n) global frequency mixing
    dlinoss::DLinOSS            # O(n) oscillatory SSM
    swattention::SWAttention    # O(nÂ·w) local attention

    # Gating
    mixture_gate::Lux.Dense

    # Output heads
    unmask_head::Lux.Dense
    confidence_head::Lux.Dense
end
```

### When to Use FNet vs Cosformer

| Use Case | Recommendation |
|----------|----------------|
| **Maximum speed** | FNet (pure) |
| **Minimum parameters** | FNet (pure) |
| **Strong frequency patterns** | FNet + DLinOSS (natural synergy) |
| **Need learned attention** | Cosformer |
| **Complex token relationships** | Cosformer |
| **Research/exploration** | Try both, compare |

### Performance Expectations

```
Speed (relative):
  Cosformer:     1.0x (baseline)
  FNet (pure):   1.5-2x faster
  FNet + weights: 1.3-1.7x faster

Parameters (relative):
  Cosformer:     1.0x (baseline, ~4dÂ² for Q/K/V/O)
  FNet (pure):   0x (no mixing params)
  FNet + weights: 0.01x (just d parameters)

Quality (estimated):
  Cosformer:     1.0x
  FNet (pure):   0.92-0.97x (per FNet paper)
  FNet + DLinOSS: possibly better for frequency-rich data
```

### References

- **FNet**: Lee-Thorp et al., ["FNet: Mixing Tokens with Fourier Transforms"](https://arxiv.org/abs/2105.03824) (NAACL 2022)
- **Cosformer**: Qin et al., ["COSFORMER: Rethinking Softmax in Attention"](https://arxiv.org/abs/2202.08791) (ICLR 2022)
- **Linear Attention**: Katharopoulos et al., ["Transformers are RNNs"](https://arxiv.org/abs/2006.16236) (ICML 2020)
- **Mask-Predict**: Ghazvininejad et al., ["Mask-Predict: Parallel Decoding"](https://arxiv.org/abs/1904.09324) (EMNLP 2019)
- **MaskGIT**: Chang et al., ["MaskGIT: Masked Generative Image Transformer"](https://arxiv.org/abs/2202.04200) (CVPR 2022)
- **Discrete Diffusion**: Austin et al., ["Structured Denoising Diffusion Models in Discrete State-Spaces"](https://arxiv.org/abs/2107.03006) (NeurIPS 2021)

---

## Deep Scaling Strategies (DeepScaling.jl)

Ossamma's O(T) complexity (vs Transformer's O(TÂ²)) allows **4-8Ã— more layers** for the same compute budget. The DeepScaling module implements strategies to leverage this advantage.

### Core Insight: Depth vs Width Trade-off

```
Transformer:  Layers = C / (TÂ² Ã— d)
Ossamma:      Layers = C / (T Ã— dÂ²)

Ratio = T / d

For T=2048, d=512: Ossamma can afford 4Ã— more layers
For T=4096, d=512: Ossamma can afford 8Ã— more layers
```

### 1. Hierarchical Frequency Ranges

Different oscillator frequency ranges per layer depth:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1-12 (early):   freq âˆˆ [1.0, 100.0]  â† Fast oscillations â”‚
â”‚                        Captures: local syntax, adjacent words   â”‚
â”‚                                                                 â”‚
â”‚  Layer 13-24 (mid):    freq âˆˆ [0.1, 22.0]   â† Medium            â”‚
â”‚                        Captures: phrases, clauses               â”‚
â”‚                                                                 â”‚
â”‚  Layer 25-48 (late):   freq âˆˆ [0.02, 5.0]   â† Slow oscillations â”‚
â”‚                        Captures: document-level, long-range     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Usage:**
```julia
using Ossamma

# Configure hierarchical frequencies
freq_config = HierarchicalFrequencyConfig(
    base_min_freq = 0.01f0,
    base_max_freq = 100.0f0,
    decay_rate = 3.0f0,
    scaling_type = :exponential  # or :linear, :logarithmic
)

# Get frequency range for a specific layer
min_freq, max_freq = compute_layer_frequencies(24, 48, freq_config)

# Print summary
frequency_summary(48, freq_config)
```

**Scaling Types:**
| Type | Behavior | Best For |
|------|----------|----------|
| `:exponential` | Fast decay early, slow late | Most cases |
| `:linear` | Uniform transition | Moderate depth |
| `:logarithmic` | Gradual decay | Very deep (96+) |

### 2. Layer Scale Initialization

Stabilizes very deep networks by scaling residual contributions:

```julia
# residual + layer_scale * block_output
# where layer_scale starts small and is learnable
```

**Configuration:**
```julia
scale_config = LayerScaleConfig(
    init_value = 0.1f0,    # Starting scale (smaller for deeper)
    learnable = true,       # Allow scale to be learned
    per_channel = true      # Per-dimension vs scalar
)
```

**Recommended init values:**
| Depth | init_value |
|-------|------------|
| 24L | 0.1 |
| 48L | 0.1 |
| 96L | 0.01 |
| 192L | 1e-4 |

### 3. Stochastic Depth (Drop Path)

Regularization by randomly skipping layers during training:

```julia
depth_config = StochasticDepthConfig(
    drop_rate = 0.1f0,     # Max drop probability (for deepest layer)
    mode = :linear         # or :uniform
)

# Linear mode: Layer 1 = 0% drop, Layer 48 = 10% drop
# Uniform mode: All layers = 10% drop
```

**Benefits:**
- Regularization (prevents overfitting)
- Faster training (fewer layers computed)
- Implicit ensemble effect

### 4. Gradient Checkpointing

Memory-efficient training by recomputing activations:

```julia
checkpoint_config = CheckpointConfig(
    checkpoint_every = 4,   # Checkpoint every 4 layers
    enabled = true
)

# Memory reduction:
# 48L without checkpoint: 48 Ã— activations
# 48L with checkpoint (every 4): 12 Ã— activations + recompute
```

### 5. OssammaBlockDeep

Deep-optimized block variant with all strategies built-in:

```julia
block = OssammaBlockDeep(
    384,                  # embedding_dimension
    4096,                 # sequence_length
    6,                    # number_of_heads
    64;                   # time_dimension
    layer_idx = 24,
    total_layers = 48,
    block_type = :global_only,  # :full, :global_only, :local_only
    freq_config = HierarchicalFrequencyConfig(),
    use_layer_scale = true,
    layer_scale_init = 0.1f0,
    use_stochastic_depth = true,
    stochastic_depth_rate = 0.1f0,
    use_parallel_scan = true,
)
```

**Block Types:**
| Type | Components | Use Case |
|------|------------|----------|
| `:full` | LinearAttn + DLinOSS + SWAttention | Full expressivity |
| `:global_only` | LinearAttn + DLinOSS | Semantic layers |
| `:local_only` | SWAttention only | Syntax layers |

### 6. Block Type Schedules

Different layer types at different depths:

```julia
# PROGRESSIVE: local â†’ global â†’ full
# Early layers: :local_only (syntax)
# Mid layers: :global_only (semantics)
# Late layers: :full (integration)

# SANDWICH: full at edges, lightweight in middle
# First/last 15%: :full
# Middle: :global_only

# ALTERNATING: cycle through types
# Every 4th: :full
# Even: :global_only
# Odd: :local_only
```

### 7. Deep Model Configurations

Pre-built configurations for common use cases:

```julia
# 48-layer deep model (~120M params)
config = deep_48L_config(
    vocab_size = 32000,
    max_sequence_length = 4096
)

# 96-layer ultra-deep (~100M params)
config = ultra_96L_config()

# Long context optimized (16K+ sequences)
config = long_context_config(
    max_sequence_length = 16384
)

# Create blocks from config
blocks = create_deep_blocks(config)

# Print summary
print_model_summary(config)
```

### Configuration Comparison

| Config | Layers | Dim | Heads | Params | Best For |
|--------|--------|-----|-------|--------|----------|
| `deep_48L` | 48 | 384 | 6 | ~120M | Starting point |
| `ultra_96L` | 96 | 256 | 4 | ~100M | Research |
| `long_context` | 32 | 512 | 8 | ~130M | 16K+ sequences |

### Example: Building a Deep Ossamma Model

```julia
using Ossamma
using Lux
using Random

# Create configuration
config = deep_48L_config(vocab_size = 32000)

# Print summary
print_model_summary(config)

# Create blocks
blocks = create_deep_blocks(config)

# Initialize
rng = Random.default_rng()
params = [Lux.initialparameters(rng, b) for b in blocks]
states = [Lux.initialstates(rng, b) for b in blocks]

# Forward pass with checkpointing (pseudo-code)
hidden = embeddings
time_emb = sinusoidal_embedding(t)

for (i, (block, ps, st)) in enumerate(zip(blocks, params, states))
    if should_checkpoint(i, CheckpointConfig())
        hidden, st = Zygote.checkpointed(block, (hidden, time_emb), ps, st)
    else
        hidden, st = block((hidden, time_emb), ps, st)
    end
    states[i] = st
end
```

### Performance Expectations

| Mode | GPU Util | Speed |
|------|----------|-------|
| Sequential OSSM | 30-35% | 7-10 sec/step |
| Parallel Scan | 80-90% | 0.5-1 sec/step |
| + Diffusion | 80-90% | 8-16Ã— faster generation |

### References

- **Layer Scale**: Touvron et al., ["Going deeper with Image Transformers"](https://arxiv.org/abs/2103.17239) (CaiT, 2021)
- **Stochastic Depth**: Huang et al., ["Deep Networks with Stochastic Depth"](https://arxiv.org/abs/1603.09382) (ECCV 2016)
- **Gradient Checkpointing**: Chen et al., ["Training Deep Nets with Sublinear Memory Cost"](https://arxiv.org/abs/1604.06174) (2016)

---

## TiDAR: Speculative Decoding with Granite (TiDAR.jl & Drafter.jl)

TiDAR (Token-level Iterative Drafting with AR Refinement) implements speculative decoding
that pairs a fast, lightweight **OssammaDrafter** model with a large **Granite** autoregressive verifier.

### High-Level System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           TiDAR Generation Loop                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚  OssammaDrafter â”‚                      â”‚   Granite AR Verifier   â”‚      â”‚
â”‚   â”‚  (~40-100M)     â”‚                      â”‚   (2B/3B/8B params)     â”‚      â”‚
â”‚   â”‚                 â”‚                      â”‚                         â”‚      â”‚
â”‚   â”‚  â€¢ O(T) complex â”‚â”€â”€â”€â”€ K tokens â”€â”€â”€â”€â”€â”€â”€>â”‚  â€¢ O(TÂ²) attention      â”‚      â”‚
â”‚   â”‚  â€¢ Parallel     â”‚     drafted          â”‚  â€¢ Sequential           â”‚      â”‚
â”‚   â”‚  â€¢ Diffusion    â”‚                      â”‚  â€¢ High quality         â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚            â”‚                                           â”‚                    â”‚
â”‚            â”‚ [MASK] â†’ predictions                      â”‚ verify logits      â”‚
â”‚            â”‚                                           â”‚                    â”‚
â”‚            v                                           v                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚   â”‚                    Rejection Sampling                          â”‚        â”‚
â”‚   â”‚  â€¢ Compare drafter vs verifier predictions                     â”‚        â”‚
â”‚   â”‚  â€¢ Accept: matching tokens (or p_ar/p_draft sampling)          â”‚        â”‚
â”‚   â”‚  â€¢ Reject: use verifier token, re-draft from that point        â”‚        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                               â”‚                                             â”‚
â”‚                               v                                             â”‚
â”‚                     [accepted tokens appended]                              â”‚
â”‚                               â”‚                                             â”‚
â”‚                         (loop until EOS)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OssammaDrafter Full Architecture

The drafter is built from **OssammaDrafterBlock** layers with time conditioning for diffusion:

```
                              token_ids (seq_len, batch)
                                        â”‚
                                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           TOKEN EMBEDDING                                     â”‚
â”‚                     Embedding(vocab_size â†’ d)                                 â”‚
â”‚                     vocab = 49155 (Granite 3.1) or 49160 (Granite 4.0)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         POSITION EMBEDDING                                    â”‚
â”‚                     Embedding(max_seq_len â†’ d)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        + (elementwise add)
                                        â”‚
                                        v
                              hidden (d, seq, batch)
                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚         t âˆˆ [0,1]                     â”‚                                       â”‚
â”‚             â”‚                         â”‚                                       â”‚
â”‚             v                         â”‚                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                                       â”‚
â”‚   â”‚ SINUSOIDAL TIME EMB â”‚             â”‚                                       â”‚
â”‚   â”‚  sin/cos encoding   â”‚             â”‚                                       â”‚
â”‚   â”‚  (time_dim = 64)    â”‚             â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                                       â”‚
â”‚             â”‚                         â”‚                                       â”‚
â”‚             v                         â”‚                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                                       â”‚
â”‚   â”‚ TIME MLP EMBEDDING  â”‚             â”‚                                       â”‚
â”‚   â”‚ Dense â†’ GELU â†’ Denseâ”‚             â”‚                                       â”‚
â”‚   â”‚ (time_dim â†’ d)      â”‚             â”‚                                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                                       â”‚
â”‚             â”‚                         â”‚                                       â”‚
â”‚   sinusoidal_emb (for blocks)         â”‚                                       â”‚
â”‚             â”‚                         â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                         â”‚
              v                         v
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                  N Ã— OssammaDrafterBlock                        â•‘
        â•‘         (6-96 layers depending on configuration)                â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                        â”‚
                                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            FINAL LAYERNORM                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              LM HEAD                                          â”‚
â”‚                         Dense(d â†’ vocab_size)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        v
                           logits (vocab, seq, batch)
```

### OssammaDrafterBlock (Single Block Detail)

Each block uses GLU-style gating between LinearAttention and DLinOSS:

```
                    Input (d, seq, batch)
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                               â”‚ (residual connection)
            v                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  TIME-CONDITIONED LAYERNORM   â”‚           â”‚
â”‚                               â”‚           â”‚
â”‚  LN(x) â†’ scale(t)Â·x + shift(t)â”‚â—„â”€â”€â”€â”€ t (time embedding)
â”‚                               â”‚           â”‚
â”‚  Also outputs Î±_bias (unused  â”‚           â”‚
â”‚  in Drafter - used in full    â”‚           â”‚
â”‚  Ossamma for branch mixing)   â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
            â”‚                               â”‚
            v                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚     GLU PROJECTION            â”‚           â”‚
â”‚     Dense(d â†’ 2d)             â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
            â”‚                               â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                         â”‚
      â”‚   split   â”‚                         â”‚
      v           v                         â”‚
   path_a      path_b                       â”‚
   (d,seq)     (d,seq)                      â”‚
      â”‚           â”‚                         â”‚
      v           v                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  LINEAR   â”‚ â”‚     DLinOSS       â”‚         â”‚
â”‚ ATTENTION â”‚ â”‚ (Oscillator SSM)  â”‚         â”‚
â”‚           â”‚ â”‚                   â”‚         â”‚
â”‚ O(n) glob â”‚ â”‚ Sequential state  â”‚         â”‚
â”‚ context   â”‚ â”‚ space model with  â”‚         â”‚
â”‚           â”‚ â”‚ damped harmonic   â”‚         â”‚
â”‚ Q,K,V,O   â”‚ â”‚ oscillators       â”‚         â”‚
â”‚ projectionsâ”‚ â”‚                  â”‚         â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
      â”‚                 â”‚                   â”‚
      â”‚            sigmoid(Â·)               â”‚
      â”‚                 â”‚                   â”‚
      â””â”€â”€â”€â”€â”€â”€ âŠ™ â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
              â”‚                             â”‚
      (Hadamard product)                    â”‚
              â”‚                             â”‚
              v                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚          DROPOUT              â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
              â”‚                             â”‚
              v                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚         SwiGLU FFN            â”‚           â”‚
â”‚                               â”‚           â”‚
â”‚  Dense(d â†’ 1.5d) â†’ split      â”‚           â”‚
â”‚       SiLU(a) âŠ™ b             â”‚           â”‚
â”‚  Dense(1.5d/2 â†’ d)            â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
              â”‚                             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€ + â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      OUTPUT LAYERNORM         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        v
               Output (d, seq, batch)
```

### Key Components Explained

#### 1. LinearAttention (O(n) Global Context)
- Provides **global context** across the sequence without O(nÂ²) cost
- Uses linear attention mechanism (no softmax)
- Processes `path_a` from the GLU split

#### 2. DLinOSS (Oscillatory State Space Model)
- **Diagonal Linear Oscillatory State Space** model
- Models temporal dependencies via damped harmonic oscillators
- Each oscillator has learnable frequency `Ï‰` and damping `Î±`
- Update: `x_t = ÏÂ·R(Î¸)Â·x_{t-1} + BÂ·u_t` where:
  - `Ï = exp(-Î±Â·Î”t)` (damping)
  - `Î¸ = Ï‰Â·Î”t` (rotation angle)
- Provides **sequential memory** that complements global attention

#### 3. GLU Gating
```
output = LinearAttention(path_a) âŠ™ sigmoid(DLinOSS(path_b))
```
- Oscillator output gates the attention output
- Sigmoid provides soft gating âˆˆ (0, 1)

#### 4. Time Conditioning (for Diffusion)
- Drafter uses diffusion-style prediction: `t=0` means "predict all masks"
- Sinusoidal embeddings encode timestep `t âˆˆ [0, 1]`
- LayerNorm is modulated by time: `scale(t)Â·LN(x) + shift(t)`

### Granite Verifier Role

**Granite** is IBM's open-source LLM family used as the AR verifier:

| Model | Params | Hidden | Layers | Vocab |
|-------|--------|--------|--------|-------|
| Granite 3.1 2B | 2B | 2048 | 40 | 49155 |
| Granite 3B MoE | 3B (800M active) | 1536 | 32 | 49155 |
| Granite 4.0 | varies | varies | varies | 49160 |
| Granite 8B | 8B | 4096 | 32 | 49155 |

**Critical**: Drafter vocabulary **must match** verifier vocabulary exactly.

### TiDAR Generation Flow

```
Step 1: DRAFTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prefix = [tokenâ‚, tokenâ‚‚, ..., tokenâ‚™]
                    â”‚
                    v
input = [tokenâ‚, tokenâ‚‚, ..., tokenâ‚™, [MASK], [MASK], ..., [MASK]]
                                       â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€ K masks â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
                    â”‚
                    v
            OssammaDrafter(input, t=0)
                    â”‚
                    v
            logits â†’ sample â†’ [draftâ‚, draftâ‚‚, ..., draftâ‚–]


Step 2: VERIFICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
full_seq = [tokenâ‚, ..., tokenâ‚™, draftâ‚, ..., draftâ‚–]
                    â”‚
                    v
            GraniteVerifier(full_seq)
                    â”‚
                    v
            verifier_logits


Step 3: ACCEPTANCE (Rejection Sampling)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For i = 1 to K:
  â”‚
  â”œâ”€ p_draft = drafter_probs[draft_i]
  â”œâ”€ p_verifier = verifier_probs[draft_i]
  â”‚
  â”œâ”€ acceptance_prob = min(1, p_verifier / p_draft)
  â”‚
  â””â”€ if rand() < acceptance_prob:
        ACCEPT draft_i
     else:
        REJECT â†’ use verifier's token, stop


Step 4: RESULT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
new_prefix = [tokenâ‚, ..., tokenâ‚™, accepted_drafts..., (verifier_token if rejected)]
                    â”‚
              (loop to Step 1)
```

### Configuration Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TiDARConfig                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ar_model: "granite_3b" | "granite_8b" | "granite4_3b"          â”‚
â”‚  vocab_size: 49155 (Granite 3.1) or 49160 (Granite 4.0)         â”‚
â”‚  mask_token_id: vocab_size (uses last token position)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DRAFTER ARCHITECTURE                                           â”‚
â”‚  â”œâ”€ embedding_dimension: 384 (narrow for speed)                 â”‚
â”‚  â”œâ”€ number_of_layers: 24-96 (deep due to O(T) complexity)       â”‚
â”‚  â”œâ”€ number_of_heads: 6                                          â”‚
â”‚  â””â”€ max_sequence_length: 4096-8192                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DEEP SCALING OPTIMIZATIONS                                     â”‚
â”‚  â”œâ”€ HierarchicalFrequencyConfig: layer-wise oscillator freqs    â”‚
â”‚  â”œâ”€ LayerScale: learnable per-layer output scaling (init=0.1)   â”‚
â”‚  â””â”€ StochasticDepth: random layer dropping during training      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  INFERENCE SETTINGS                                             â”‚
â”‚  â”œâ”€ draft_length: 8-12 tokens per step                          â”‚
â”‚  â”œâ”€ temperature: 0.9                                            â”‚
â”‚  â””â”€ confidence_threshold: 0.8                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Architecture?

1. **Speed**: Drafter uses O(T) complexity (DLinOSS + LinearAttention), enabling 48-96 layers where a Transformer would be impractical

2. **Quality**: Granite verifier ensures output quality matches the large model

3. **Efficiency**: Most tokens are accepted, so the slow verifier runs infrequently

4. **Parallel Drafting**: Unlike AR models, drafter predicts K tokens simultaneously

### Why Deep Ossamma for TiDAR?

| Aspect | Transformer Drafter | Ossamma Drafter |
|--------|---------------------|-----------------|
| Complexity | O(TÂ² Ã— d) | **O(T Ã— dÂ²)** |
| Layers for 80M params | 12L Ã— 512d | **48L Ã— 384d** |
| Parallel draft | Limited | **Full (diffusion)** |
| GPU utilization | 80% | **80%+ (parallel scan)** |

### Quick Start

```julia
using Ossamma

# Create deep drafter for Granite 3B
config = granite_3b_drafter_deep_config()
print_tidar_config(config)

# Create model
drafter = OssammaDrafterDeep(config)

# Initialize
rng = Random.default_rng()
params = Lux.initialparameters(rng, drafter)
state = Lux.initialstates(rng, drafter)

# Draft tokens
prefix = [1, 2, 3, 4, 5]  # Token IDs
drafted_ids, logits, new_state = draft_tokens(
    drafter, prefix, 8, params, state;
    temperature = 0.9f0
)
```

### TiDAR Inference Loop

```julia
# Pseudo-code for full TiDAR generation

function tidar_generate(drafter, verifier, prompt_ids, max_length)
    prefix = prompt_ids
    drafter_state = initial_state

    while length(prefix) < max_length
        # One TiDAR step
        prefix, accepted, drafter_state = tidar_generate_step(
            drafter, drafter_params, drafter_state,
            verifier,  # Function: ids -> logits
            prefix,
            config.draft_length;
            temperature = config.temperature
        )

        # Stats
        total_tokens += accepted + 1  # accepted + verifier's correction
    end

    return prefix
end
```

### Configuration Options

```julia
# Standard drafter (24L, ~50M params)
config = granite_3b_drafter_config()

# Deep drafter (48L, ~80M params) - recommended
config = granite_3b_drafter_deep_config()

# Custom configuration
config = TiDARConfig(
    ar_model = "granite_3b",
    vocab_size = GRANITE_VOCAB_SIZE,  # 49155
    embedding_dimension = 384,
    number_of_layers = 48,
    number_of_heads = 6,
    max_sequence_length = 4096,

    # Deep scaling
    use_layer_scale = true,
    layer_scale_init = 0.1f0,
    use_stochastic_depth = true,
    stochastic_depth_rate = 0.1f0,
    freq_config = HierarchicalFrequencyConfig(
        base_min_freq = 0.01f0,
        base_max_freq = 100.0f0,
        scaling_type = :exponential
    ),

    # TiDAR settings
    draft_length = 12,
    confidence_threshold = 0.8f0,
    temperature = 0.9f0,
)
```

### Drafter Model Variants

| Config Function | Layers | Dim | Params | Best For |
|-----------------|--------|-----|--------|----------|
| `granite_2b_drafter_config()` | 24 | 384 | ~40M | Granite 2B verifier |
| `granite_3b_drafter_config()` | 32 | 384 | ~60M | Granite 3B verifier |
| `granite_4_3b_drafter_config()` | 32 | 384 | ~60M | Granite 4.0 verifier |
| `granite_8b_drafter_config()` | 48 | 384 | ~80M | Granite 8B verifier |
| `granite_drafter_deep_config()` | 48-96 | 384 | ~80-100M | Maximum acceptance |

### Expected Performance

| Metric | Value |
|--------|-------|
| Drafter params | ~40-100M |
| Verifier params | 2B-8B (Granite) |
| Draft length | 8-12 tokens |
| Acceptance rate | ~60-80% |
| Speedup vs AR | **2-4Ã—** |

### Training the Drafter

The drafter is trained with MLM loss on the same data as the verifier:

```julia
using Ossamma

# Create drafter
config = granite_3b_drafter_deep_config()
drafter = OssammaDrafterDeep(config)

# Training config
train_config = DrafterTrainingConfig(
    learning_rate = 1e-4,
    batch_size = 32,
    mask_ratio = 0.15,  # 15% tokens masked
    # ...
)

# Training loop uses drafter_mlm_loss from DrafterTraining module
```

### Key Differences: OssammaDrafter vs Full OssammaBlock

| Feature | Full OssammaBlock | OssammaDrafterBlock |
|---------|-------------------|---------------------|
| SWAttention (local) | âœ“ | âœ— (verifier handles local) |
| Î±-mixing gating | âœ“ | âœ— (standard residual) |
| Branches | 2 (Global + Local) | 1 (Global only) |
| Use case | General LM | Fast drafting |

### References

- **Speculative Decoding**: Leviathan et al., ["Fast Inference from Transformers via Speculative Decoding"](https://arxiv.org/abs/2211.17192) (ICML 2023)
- **TiDAR (conceptual basis)**: Token-level iterative draft and refine
- **Granite Models**: IBM's Granite 3.1/4.0 family

---

## NER Model Benchmark Findings (2024-12-28)

### Checkpoint: `checkpoints/ner_110m/checkpoint_best.jls`

**Model Architecture** (from checkpoint step 48500):
| Parameter | Value |
|-----------|-------|
| Embedding Dimension | 640 |
| Number of Layers | 10 |
| Number of Heads | 10 |
| Time Dimension | 192 |
| State Dimension | 640 |
| Window Size | 32 |
| Max Sequence Length | 256 |
| FFN Expansion | 1.334375 |
| Vocab Size | 2004 |

**Speed Benchmark** (CPU only, no GPU):
- Throughput: **15.3 tokens/sec** (1.5 sentences/sec)
- Average inference time: **653ms Â± 132ms** per sentence

**Accuracy Benchmark**:
- F1 Score: **0%**
- Recall: 0%
- Precision: 0%

### Root Cause: Synthetic Vocabulary

The model was trained with the `--synthetic` flag, which generates placeholder tokens:
```julia
# From generate_synthetic_data() in train_ner_production.jl:269
tokens = ["token_$i" for i in rand(1:vocab_size, seq_len)]
```

**Vocab Contents** (from checkpoint):
```
"token_1406" => 210
"token_1202" => 325
"token_1032" => 1681
...
```

This means:
1. All real English words map to `[UNK]` (token ID 2)
2. The model only learned patterns on synthetic token IDs
3. Embeddings are random for real language input
4. The checkpoint is **not usable for real NER tasks**

### Required Actions

To make the NER model functional:

1. **Retrain with real data**: Use `data/rag/synthetic_work.jsonl` (contains actual English words despite the name):
   ```bash
   julia --project=. scripts/train_ner_production.jl  # Without --synthetic flag
   ```

2. **Ensure data path exists**: The training script falls back to synthetic data if `config.data_dir` doesn't exist

3. **Build proper vocabulary**: From the actual training corpus using `build_vocab()` function

### Files Modified for Benchmark

- `scripts/benchmark_ner.jl` - NER speed/accuracy benchmark
- `scripts/debug_predictions.jl` - Debugging script for model outputs
- `scripts/train_ner_production.jl` - Added `use_ffn`/`ffn_expansion` fields to `TrainingConfig` for checkpoint compatibility
